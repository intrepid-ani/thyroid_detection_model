{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkttkrH4Kq43"
      },
      "outputs": [],
      "source": [
        "#@title Import librarys\n",
        "from joblib import parallel_backend\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import r2_score, classification_report, accuracy_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initialize Variables\n",
        "path= \"/content/thyroidDF.csv\"\n",
        "data = pd.read_csv(path)\n",
        "df = data.copy(True)\n",
        "le = LabelEncoder()"
      ],
      "metadata": {
        "id": "LCddT2HoLB85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data cleaning\n"
      ],
      "metadata": {
        "id": "o1kki3IvhsXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Understand data\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "kIfenKGgkt5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title `head()`\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "qqsPD1pOwuK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Find `columns`\n",
        "col = df.columns\n",
        "col"
      ],
      "metadata": {
        "id": "37CivOIDdS-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Ploting the number of `null values`\n",
        "def plotna(data = df, col=col):\n",
        "  nulV = data.isna().sum()\n",
        "  plt.bar(col, nulV)\n",
        "  plt.xlabel(\"Columns\")\n",
        "  plt.ylabel(\"Number of null values\")\n",
        "  plt.xticks(rotation=90, ha='right')\n",
        "  plt.show()\n",
        "\n",
        "plotna(df, col)\n",
        "plot = 0"
      ],
      "metadata": {
        "id": "3mXwWhhddCMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title `shape` <b>Before Cleaning the data </b>\n",
        "df.shape"
      ],
      "metadata": {
        "id": "KtyOAhHIsL_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title `describe()`\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "PgaXgJXiwQhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  `info()`\n",
        "df.info()"
      ],
      "metadata": {
        "id": "N4qjgpaQU30i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b>Five summary</B>\n",
        "summary = df.describe()"
      ],
      "metadata": {
        "id": "ZnBnhRQ6FsaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title <b>Visualization</b> of 5 Summary\n",
        "\n",
        "for i in summary.columns:\n",
        "    q1 = df[i].quantile(0.25)\n",
        "    q3 = df[i].quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    lower_bound = q1 - 1.5 * iqr\n",
        "    upper_bound = q3 + 1.5 * iqr\n",
        "\n",
        "    # Filter the data\n",
        "    filtered_data = df[(df[i] >= lower_bound) & (df[i] <= upper_bound)]\n",
        "\n",
        "    # Create subplots\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))  # 1 row, 2 columns\n",
        "\n",
        "    # Seaborn Boxplot\n",
        "    sns.boxplot(x=filtered_data[i], width = 0.35, ax= axes[0],color=\"lightblue\")\n",
        "    axes[0].set_xlabel(f\"{i} Levels\")\n",
        "    axes[0].set_title(f\"Box Plot of {i} Levels (Outliers Removed)\")\n",
        "\n",
        "    # Seaborn Histogram\n",
        "    sns.histplot(filtered_data[i], bins=20, kde=True, ax=axes[1], color=\"red\")\n",
        "    axes[1].set_xlabel(f\"{i} Levels\")\n",
        "    axes[1].set_title(f\"Distribution of {i}\")\n",
        "\n",
        "    # Adjust layout and show\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "KlYuG5BzyuWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##Eliminate Null Value\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S0_5CAApPB5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plotna()"
      ],
      "metadata": {
        "id": "xXKYjvRqgyN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cleaning ` Age ` column\n",
        "df = df[df['age'] <=100] # Removing elements where the age is more than 100\n",
        "df.age.isna().sum()"
      ],
      "metadata": {
        "id": "jjLTd2cdskd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cleaning `Gender` column\n",
        "df = df.dropna(subset = ['sex'])"
      ],
      "metadata": {
        "id": "yKgTDNiLPB8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "No need to Clean ['query_on_thyroxine',\n",
        "       'on_antithyroid_meds', 'sick', 'pregnant', 'thyroid_surgery',\n",
        "       'I131_treatment', 'query_hypothyroid', 'query_hyperthyroid', 'lithium',\n",
        "       'goitre', 'tumor', 'hypopituitary', 'psych', 'TSH_measured',]\n",
        " \"\"\""
      ],
      "metadata": {
        "id": "knJzIoz5gdj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.hypopituitary.unique()"
      ],
      "metadata": {
        "id": "Frm2plMJfWD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['TSH'].isna().sum()"
      ],
      "metadata": {
        "id": "kkBFGPCzgdgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Chaning NaN of `TSH,'T3', 'TT4', 'T4U', 'FTI', 'TBG'` columns to there median respectively\n",
        "\n",
        "features_to_impute = ['TSH', 'T3', 'TT4', 'T4U', 'FTI']\n",
        "for feature in features_to_impute:\n",
        "    df[feature] = df[feature].fillna(df[feature].median())"
      ],
      "metadata": {
        "id": "DqmFXwChgdZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Drop `TBG` column as <b>too many NaN Values<b>\n",
        "df = df.drop(columns=['TBG'])"
      ],
      "metadata": {
        "id": "q6pxePhTgdXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col = df.columns #Re-checking columns since we droped `TBG`"
      ],
      "metadata": {
        "id": "YgreSn6w1GrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotna(df, col)"
      ],
      "metadata": {
        "id": "ppRlKaidgdTz",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.target.unique()"
      ],
      "metadata": {
        "id": "L6Jh5h6saOrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###There is a problem in the dataset <b>in target column as the unique values are `['-', 'S', 'F', 'AK', 'R', 'I', 'M', 'N', 'G', 'K', 'A', 'L', 'MK','Q', 'J', 'C|I', 'O', 'LJ', 'H|K', 'GK', 'MI', 'KJ', 'P', 'FK','B', 'GI', 'C', 'GKJ', 'OI', 'D|R', 'D', 'E']`</b>"
      ],
      "metadata": {
        "id": "mpuzLE0o5SbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df = df.dropna()\n",
        "# df.target.isna().sum()"
      ],
      "metadata": {
        "id": "ogbj64P9NHBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#### Hurray!!! Data Is Clean And Ready To Use  \n",
        "---"
      ],
      "metadata": {
        "id": "jvTqQM04gdRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Removing Unwanted data `'patient_id', 'TBG_measured', 'TSH_measured', 'T3_measured', 'TT4_measured', 'T4U_measured', 'FTI_measured', 'referral_source'`\n",
        "# Drop irrelevant and redundant columns\n",
        "columns_to_drop = [\n",
        "    'patient_id', 'TBG_measured', 'TSH_measured', 'T3_measured',\n",
        "    'TT4_measured', 'T4U_measured', 'FTI_measured', 'referral_source'\n",
        "]\n",
        "\n",
        "# Remove unwanted columns\n",
        "df = df.drop(columns=columns_to_drop)"
      ],
      "metadata": {
        "id": "aTtA4TNo0qS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.hypopituitary.count()"
      ],
      "metadata": {
        "id": "Gmr0NHZG083z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Encoding Data using `LabelEncoder`\n",
        "---"
      ],
      "metadata": {
        "id": "2UjhETn8gdOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binary_cols = [\n",
        "    'sex', 'on_thyroxine', 'query_on_thyroxine', 'on_antithyroid_meds', 'sick',\n",
        "    'pregnant', 'thyroid_surgery', 'I131_treatment', 'query_hypothyroid',\n",
        "    'query_hyperthyroid', 'lithium', 'goitre', 'tumor', 'hypopituitary', 'psych', 'target'\n",
        "]\n",
        "\n",
        "label_encoders = {}\n",
        "for col in binary_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])  # Encode each binary column\n",
        "    label_encoders[col] = le12345678910"
      ],
      "metadata": {
        "id": "SUnpnIch3MUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Scaling columns using `MinMaxScaler`\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "numerical_features = ['TSH', 'T3', 'TT4', 'T4U', 'FTI']\n",
        "df[numerical_features] = scaler.fit_transform(df[numerical_features])"
      ],
      "metadata": {
        "id": "MMjLJbfy0-8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "wJ7G6RUO0_Dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding the Covariance of feature\n",
        "---"
      ],
      "metadata": {
        "id": "M6S6oHLSs-g0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming `data` is your dataset with features and target combined\n",
        "plt.figure(figsize=(10, 8))\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Use Seaborn to create the heatmap\n",
        "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True)\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_wTNesq8if6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix.target"
      ],
      "metadata": {
        "id": "e2ITTKLetQGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create Models\n",
        "---\n",
        "\n",
        "*   <b>Linear regression(<i>Multiple</i>)\n",
        "*   KNN\n",
        "*   SVM\n",
        "*   Decision Tree</b>\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "NcMxxskl0_Il"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Regression\n",
        "---"
      ],
      "metadata": {
        "id": "zVar9p9l0_MV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_column = 'target'\n",
        "\n",
        "X = df.drop(columns=['target'])\n",
        "y = df[target_column]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "yJE16kG30_Qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LinearRegression_model = LinearRegression()\n",
        "LinearRegression_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "9jM1kTpoMzAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred = LinearRegression_model.predict(X)\n",
        "linear_result = r2_score(y, ypred)\n",
        "print(\"R^2 Score:\", linear_result)"
      ],
      "metadata": {
        "id": "PzssAk2z0_Uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "##KNN\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "YUBCzPlFDirK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "KNN_model = KNeighborsClassifier(n_neighbors= 3, metric='euclidean')\n",
        "KNN_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "D1eRdHADDita"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred = KNN_model.predict(X)\n",
        "print(ypred)"
      ],
      "metadata": {
        "id": "NHoemQcP1K-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_result = accuracy_score(y, ypred)\n",
        "knn_result"
      ],
      "metadata": {
        "id": "6X-XB6SV1K7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "##SVM\n",
        "---\n",
        "* Linear SVM\n",
        "* Non-Linear SVM"
      ],
      "metadata": {
        "id": "utSRrXrG1K5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Linear SVM\n",
        "LinearSVC_model = LinearSVC()\n",
        "LinearSVC_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "LP9uvMDj1K2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred = LinearSVC_model.predict(X)\n",
        "linear_svm_result = accuracy_score(y, ypred)\n",
        "linear_svm_result"
      ],
      "metadata": {
        "id": "8i9bkp0z1Kza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y, ypred)"
      ],
      "metadata": {
        "id": "JQpryGsE1Kws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Non-linear *SVM*"
      ],
      "metadata": {
        "id": "MhTkUdi3L1lK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Finding the best degree\n",
        "# for i in range(50):\n",
        "#   model = SVC (kernel = 'poly', degree = ).fit(X, y)\n",
        "#   print(\"POLY3: \",i , model.score(X_train, y_train))\n",
        "\n",
        "# Just to find out the best suitable degree"
      ],
      "metadata": {
        "id": "ocsLHKAm1Kth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title SVM using `Radial Basis Function` ' rbf ' kernel\n",
        "RBFSVM_model = SVC (kernel = \"rbf\").fit(X, y)"
      ],
      "metadata": {
        "id": "W3kSbkFCKTkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rbf_result = RBFSVM_model.score(X, y)\n",
        "rbf_result"
      ],
      "metadata": {
        "id": "OEztE8B6LK0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title SVM using `Polynomial` ' poly ' where the best <b><u>degree is 15</u></b> kernel\n",
        "# But it requires high computational power\n",
        "# PolynomialSVM_model = SVC (kernel = \"poly\", degree= 15).fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Use multiple CPU cores for computation\n",
        "with parallel_backend('loky', n_jobs=-1):\n",
        "    PolynomialSVM_model = SVC(kernel=\"poly\", degree=15).fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "mx-Q8yg4Ntsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly_result = PolynomialSVM_model.score(X, y)\n",
        "poly_result"
      ],
      "metadata": {
        "id": "pwExVb3YODVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Decision Tree\n",
        "---"
      ],
      "metadata": {
        "id": "-SeA65XZSp5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DecisionTree_model= DecisionTreeClassifier()\n",
        "DecisionTree_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "PN6_WsMNSsC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred = DecisionTree_model.predict(X)\n",
        "decision_tree_result = accuracy_score(ypred, y)"
      ],
      "metadata": {
        "id": "eT_iMMpTSr_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing the performance of all the models"
      ],
      "metadata": {
        "id": "WF06Iei0oguA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data\n",
        "results = [linear_result, knn_result, linear_svm_result, rbf_result,  poly_result, decision_tree_result]\n",
        "names = ['LinearRegression', 'KNN', 'LinearSVM', 'RBFSVM', 'PolynomialSVM', 'DecisionTree']\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x=names, y=results, color=\"lightgreen\")\n",
        "\n",
        "# Adding titles and labels\n",
        "plt.title(\"Comparison of Model Results\", fontsize=16)\n",
        "plt.xlabel(\"Models\", fontsize=14)\n",
        "plt.ylabel(\"Results\", fontsize=14)\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels if needed\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "for i in range(len(results)):\n",
        "  print(f\"Result of {names[i]} : {results[i]}\" )\n"
      ],
      "metadata": {
        "id": "gYcGlCyzo4T-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coping models to `thyroid_dection_models` using dictionary dataStructure"
      ],
      "metadata": {
        "id": "jyak8VY4njzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_list = [LinearRegression_model, KNN_model, LinearSVC_model, RBFSVM_model, PolynomialSVM_model, DecisionTree_model]\n",
        "model_name = ['LinearRegression_model', 'KNN_model', 'LinearSVC_model', 'RBFSVM_model', 'PolynomialSVM_model', 'DecisionTree_model']\n",
        "models = {}\n",
        "for i in range(len(model_list)):\n",
        "  models[model_name[i]] = list((model_list[i], results[i]))\n",
        "\n",
        "\n",
        "models"
      ],
      "metadata": {
        "id": "mmeWJZpwFJT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create the `thyroid_detection_models.pkl`\n",
        "file_name = \"models_accuracy_scale.pkl\"\n",
        "with open(file_name, \"wb\") as file:\n",
        "    pickle.dump({'models': models, 'scaler': scaler}, file)\n",
        "\n",
        "print(f\"Model saved as '{file_name}'\")"
      ],
      "metadata": {
        "id": "NUXtLPbYn0bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Test the model from the pickle file\n",
        "with open(file_name, \"rb\") as file:\n",
        "    loaded_model = pickle.load(file)\n",
        "\n",
        "# Use the loaded model for predictions\n",
        "ypred= loaded_model['models']['DecisionTree_model'][1]"
      ],
      "metadata": {
        "id": "b0M3Gam4G-sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(ypred, y)"
      ],
      "metadata": {
        "id": "ZWLPmLe5G-zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model['scaler']"
      ],
      "metadata": {
        "id": "jR4y8YGvG-18"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}